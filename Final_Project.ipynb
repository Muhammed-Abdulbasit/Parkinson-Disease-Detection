{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4eb3fae-5f26-44f1-a6bf-d22cf55703f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Parkinsson_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac18c8fc-455b-4a37-8a0f-5693648876c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 195\n",
      "Number of columns: 24\n",
      "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
      "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
      "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
      "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
      "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
      "\n",
      "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
      "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
      "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
      "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
      "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
      "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
      "\n",
      "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
      "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
      "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
      "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
      "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
      "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.266482  2.301442  0.284654  \n",
      "1  0.335590  2.486855  0.368674  \n",
      "2  0.311173  2.342259  0.332634  \n",
      "3  0.334147  2.405554  0.368975  \n",
      "4  0.234513  2.332180  0.410335  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      " Summary statistics for numeric columns:\n",
      "\n",
      "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "count   195.000000    195.000000    195.000000      195.000000   \n",
      "mean    154.228641    197.104918    116.324631        0.006220   \n",
      "std      41.390065     91.491548     43.521413        0.004848   \n",
      "min      88.333000    102.145000     65.476000        0.001680   \n",
      "25%     117.572000    134.862500     84.291000        0.003460   \n",
      "50%     148.790000    175.829000    104.315000        0.004940   \n",
      "75%     182.769000    224.205500    140.018500        0.007365   \n",
      "max     260.105000    592.030000    239.170000        0.033160   \n",
      "\n",
      "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
      "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
      "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
      "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
      "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
      "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
      "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
      "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
      "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
      "\n",
      "       MDVP:Shimmer(dB)  ...  Shimmer:DDA         NHR         HNR      status  \\\n",
      "count        195.000000  ...   195.000000  195.000000  195.000000  195.000000   \n",
      "mean           0.282251  ...     0.046993    0.024847   21.885974    0.753846   \n",
      "std            0.194877  ...     0.030459    0.040418    4.425764    0.431878   \n",
      "min            0.085000  ...     0.013640    0.000650    8.441000    0.000000   \n",
      "25%            0.148500  ...     0.024735    0.005925   19.198000    1.000000   \n",
      "50%            0.221000  ...     0.038360    0.011660   22.085000    1.000000   \n",
      "75%            0.350000  ...     0.060795    0.025640   25.075500    1.000000   \n",
      "max            1.302000  ...     0.169420    0.314820   33.047000    1.000000   \n",
      "\n",
      "             RPDE         DFA     spread1     spread2          D2         PPE  \n",
      "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000  \n",
      "mean     0.498536    0.718099   -5.684397    0.226510    2.381826    0.206552  \n",
      "std      0.103942    0.055336    1.090208    0.083406    0.382799    0.090119  \n",
      "min      0.256570    0.574282   -7.964984    0.006274    1.423287    0.044539  \n",
      "25%      0.421306    0.674758   -6.450096    0.174351    2.099125    0.137451  \n",
      "50%      0.495954    0.722254   -5.720868    0.218885    2.361532    0.194052  \n",
      "75%      0.587562    0.761881   -5.046192    0.279234    2.636456    0.252980  \n",
      "max      0.685151    0.825288   -2.434031    0.450493    3.671155    0.527367  \n",
      "\n",
      "[8 rows x 23 columns]\n",
      "\n",
      "Check for missing values:\n",
      "\n",
      "name                0\n",
      "MDVP:Fo(Hz)         0\n",
      "MDVP:Fhi(Hz)        0\n",
      "MDVP:Flo(Hz)        0\n",
      "MDVP:Jitter(%)      0\n",
      "MDVP:Jitter(Abs)    0\n",
      "MDVP:RAP            0\n",
      "MDVP:PPQ            0\n",
      "Jitter:DDP          0\n",
      "MDVP:Shimmer        0\n",
      "MDVP:Shimmer(dB)    0\n",
      "Shimmer:APQ3        0\n",
      "Shimmer:APQ5        0\n",
      "MDVP:APQ            0\n",
      "Shimmer:DDA         0\n",
      "NHR                 0\n",
      "HNR                 0\n",
      "status              0\n",
      "RPDE                0\n",
      "DFA                 0\n",
      "spread1             0\n",
      "spread2             0\n",
      "D2                  0\n",
      "PPE                 0\n",
      "dtype: int64\n",
      "\n",
      "Get information on the DataFrame's columns, types, non-null values, etc:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n Summary statistics for numeric columns:\\n\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nCheck for missing values:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nGet information on the DataFrame's columns, types, non-null values, etc:\\n\")print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7547490-ffb9-4d89-9055-ff839aaf4ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data shape: (195, 24)\n",
      "Data with no outliers shape: (114, 24)\n",
      "Data with capped outliers shape: (195, 23)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "Q1 = numeric_df.quantile(0.25)\n",
    "Q3 = numeric_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the outlier step\n",
    "outlier_step = 1.5 * IQR\n",
    "\n",
    "# Identify and remove outliers in the numeric columns\n",
    "filtered_df = df[~((numeric_df < (Q1 - outlier_step)) | (numeric_df > (Q3 + outlier_step))).any(axis=1)]\n",
    "\n",
    "# Alternatively, cap the outliers in the numeric columns\n",
    "capped_df = numeric_df.apply(lambda x: x.clip(lower=x.quantile(0.25) - 1.5 * (x.quantile(0.75) - x.quantile(0.25)),\n",
    "                                                upper=x.quantile(0.75) + 1.5 * (x.quantile(0.75) - x.quantile(0.25))))\n",
    "\n",
    "# Replace the original numeric columns in df with the capped values\n",
    "df.update(capped_df)\n",
    "\n",
    "# Display the shapes of the original and cleaned dataframes\n",
    "print(\"Original Data shape:\", df.shape)\n",
    "print(\"Data with no outliers shape:\", filtered_df.shape)\n",
    "print(\"Data with capped outliers shape:\", capped_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1ea09e8-4236-41b4-b93d-336aa96467a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0  phon_R01_S01_1    -0.829300     -0.436165     -0.952037        0.334914   \n",
      "1  phon_R01_S01_2    -0.770972     -0.530974     -0.057721        0.715418   \n",
      "2  phon_R01_S01_3    -0.909476     -0.723168     -0.109875        0.884991   \n",
      "3  phon_R01_S01_4    -0.909622     -0.649092     -0.114229        0.775389   \n",
      "4  phon_R01_S01_5    -0.925657     -0.606245     -0.130608        1.368893   \n",
      "\n",
      "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
      "0          0.749759  0.132963  0.760800    0.131755      0.745985  ...   \n",
      "1          1.037674  0.453892  1.276809    0.452684      1.681731  ...   \n",
      "2          1.325589  0.720770  1.585687    0.721813      1.202693  ...   \n",
      "3          1.325589  0.578885  1.284076    0.577677      1.340396  ...   \n",
      "4          1.901418  1.095750  2.047187    1.096793      1.836448  ...   \n",
      "\n",
      "   Shimmer:DDA       NHR       HNR    status      RPDE       DFA   spread1  \\\n",
      "0     0.607532 -0.067893 -0.193225  0.571429 -0.807838  1.760814  0.801323   \n",
      "1     1.548254 -0.137843 -0.634508  0.571429 -0.387524  1.837562  1.479853   \n",
      "2     1.175323 -0.291633 -0.279760  0.571429 -0.662075  1.942048  1.141445   \n",
      "3     1.340229 -0.280719 -0.281346  0.571429 -0.613134  1.832380  1.440945   \n",
      "4     1.899461 -0.178026 -0.506745  0.571429 -0.783021  1.909364  1.780940   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.480477 -0.210531  0.868886  \n",
      "1  1.311185  0.275077  1.803605  \n",
      "2  1.017682 -0.103629  1.402661  \n",
      "3  1.293840  0.062145  1.806954  \n",
      "4  0.096195 -0.130026  2.267082  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(numeric_df)  # Returns an array\n",
    "\n",
    "# Create a new DataFrame for the scaled values using the columns from numeric_df\n",
    "df_scaled_numeric = pd.DataFrame(scaled_values, columns=numeric_df.columns)\n",
    "\n",
    "# Update the original df with the scaled numeric values\n",
    "# df.update(df_scaled_numeric)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22040bcb-dbb2-4867-af91-7715950cfad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features by RFE: Index(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'Jitter:DDP', 'MDVP:APQ',\n",
      "       'Shimmer:DDA', 'spread1', 'spread2', 'D2', 'PPE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Ensure 'status' is an integer type if it's not already\n",
    "df_scaled_numeric['status'] = df_scaled_numeric['status'].astype(int)\n",
    "\n",
    "# Separate the features (X) and the target label (y)\n",
    "X = df_scaled_numeric.drop('status', axis=1)\n",
    "y = df_scaled_numeric['status']\n",
    "\n",
    "# Create a RandomForestClassifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# RFE model to select top 10 features, adjust the number as needed\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Summarize all selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected features by RFE:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d62ac8f-e515-4114-8db2-f0e2ee77a9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 important features:\n",
      "          Feature  Importance\n",
      "21           PPE    0.125544\n",
      "18       spread1    0.112966\n",
      "0    MDVP:Fo(Hz)    0.093059\n",
      "2   MDVP:Flo(Hz)    0.060841\n",
      "19       spread2    0.058013\n",
      "1   MDVP:Fhi(Hz)    0.046030\n",
      "12      MDVP:APQ    0.045509\n",
      "7     Jitter:DDP    0.040051\n",
      "14           NHR    0.038418\n",
      "5       MDVP:RAP    0.038368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance_sorted = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 10 most important features, adjust the number as needed\n",
    "print(\"Top 10 important features:\\n\", feature_importance_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e6c1435-41c9-40cb-8563-4c6e2823c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.43      0.60         7\n",
      "           0       0.89      1.00      0.94        32\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.94      0.71      0.77        39\n",
      "weighted avg       0.91      0.90      0.88        39\n",
      "\n",
      "Accuracy: 0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare the data\n",
    "X = df_scaled_numeric[selected_features]\n",
    "y = df_scaled_numeric['status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52c1bf66-fdc1-45ae-a2de-e8a26736a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.57      0.67         7\n",
      "           0       0.91      0.97      0.94        32\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.86      0.77      0.80        39\n",
      "weighted avg       0.89      0.90      0.89        39\n",
      "\n",
      "Accuracy: 0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "dt_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, dt_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b7bece5-63f2-4589-a2cf-6faa37570005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.71      0.77         7\n",
      "           0       0.94      0.97      0.95        32\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.89      0.84      0.86        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "Accuracy: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "knn_pred = knn.predict(X_test)\n",
    "print(\"K-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, knn_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d872cc11-585a-4e51-90f6-4d4f4e7fe829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.57      0.53         7\n",
      "           0       0.90      0.88      0.89        32\n",
      "\n",
      "    accuracy                           0.82        39\n",
      "   macro avg       0.70      0.72      0.71        39\n",
      "weighted avg       0.83      0.82      0.83        39\n",
      "\n",
      "Accuracy: 0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "nb_pred = nb.predict(X_test)\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, nb_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11c64bd2-921e-4173-90de-25c91470df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best parameters found:  {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best score from grid search:  0.9166666666666666\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END .max_depth=30, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=30, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, min_samples_split=10, n_estimators=200; total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score from grid search: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5803cc-f544-4e4b-bd93-9b56798c2216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
